## Model selection

```{r, echo=FALSE}}
source("../R/MS_functions.R")
```


### Preprocessing
With a view to training the model, we apply **one-hot encoding**.

Based on the Exploratory Data Analysis (EDA), we selected only the most relevant variables and according to the following patterns:

* People with a university degree or a professional training course are more likely to subscribe.
* Individuals who are students or retired show a higher tendency to subscribe.
* There are more subscriptions in the `months` of September, October, December, and March.
* People who in the `previous campaign` either subscribed or refused are more likely to subscribe, compared to those who were not contacted.
* `cons.price.idx` values greater than 93 are linked to a higher chance of subscription.
* `cons.conf.idx` values above the median are associated with a higher likelihood of subscription.
* `euribor3m` values below the mean correspond to a higher probability of subscription.
* `emp.var.rate` values below 0 are more likely to be associated with subscription.

We transform these continuous variables into binary indicators reflecting these insights. 
```{r echo=FALSE}
train_bin <- train

train_bin$cons.price.idx <- ifelse(train_bin$cons.price.idx < 93, 1, 0)
names(train_bin)[names(train_bin) == "cons.price.idx"] <- "low_cpi"

train_bin$cons.conf.idx <- ifelse(train_bin$cons.conf.idx > median(train$cons.conf.idx), 1, 0)
names(train_bin)[names(train_bin) == "cons.conf.idx"] <- "high_cci"

train_bin$euribor3m <- ifelse(train_bin$euribor3m < mean(train$euribor3m), 1, 0)
names(train_bin)[names(train_bin) == "euribor3m"] <- "low_euribor"

train_bin$emp.var.rate <- ifelse(train_bin$emp.var.rate < 0, 1, 0)
names(train_bin)[names(train_bin) == "emp.var.rate"] <- "negative_emp"

train_bin$university<-ifelse(train_bin$education=='university.degree', 1, 0)
train_bin$p_course<-ifelse(train_bin$education=='professional.course', 1, 0)
train_bin <- subset(train_bin, select = -education)

train_bin$job_student <- ifelse(train_bin$job == "student", 1, 0)
train_bin$job_retired <- ifelse(train_bin$job == "retired", 1, 0)
train_bin$job_admin <- ifelse(train_bin$job == "admin.", 1, 0)
train_bin <- subset(train_bin, select = -job)

train_bin$month_sep <- ifelse(train_bin$month == "sep", 1, 0)
train_bin$month_oct <- ifelse(train_bin$month == "oct", 1, 0)
train_bin$month_dec <- ifelse(train_bin$month == "dec", 1, 0)
train_bin$month_mar <- ifelse(train_bin$month == "mar", 1, 0)

train_bin$p_failure <- ifelse(train_bin$poutcome == "failure", 1, 0)
train_bin$p_success <- ifelse(train_bin$poutcome == "success", 1, 0)
train_bin <- subset(train_bin, select = -poutcome)
```

```{r echo=FALSE}
drop_var<-c("marital", "default", 'housing' ,"loan", 
            "contact","day_of_week", "month", "campaign",  "nr.employed", 'job', "duration", "pdays")

full_df <- train_bin[, !(names(train_bin) %in% drop_var)]
full_df$target <-ifelse(subscribed=='yes', 1, 0)
full_df<-full_df[, !(names(full_df)) %in% 'subscribed']
detach(train)
attach(full_df)
```

We obtain the following dataset:
```{r echo=FALSE}
str(full_df)
```

### STEPWISE selection

```{r}
full_model <- glm(target ~ ., data = full_df, family = binomial)
stepwise <- stepAIC(full_model, direction = "both", trace = FALSE)
vif(stepwise)

# predictore removed by Stepwise
stepwise$anova

stepwise_formula <- target ~ single + cellular + low_call + previous + negative_emp + 
  low_cpi + high_cci + low_euribor + university + p_course + 
  job_student + job_retired + job_admin + month_sep + month_oct + 
  month_dec + month_mar + p_failure + p_success
```

### LASSO selection
```{r}
set.seed(123)

df_no_target <- subset(full_df, select = -target)

fit_lasso <- glmnet(x = as.matrix(df_no_target),
                    y = target,
                    alpha = 1,
                    family = "binomial",
)

cv_fit <- cv.glmnet(
  x = as.matrix(df_no_target),
  y = target,
  alpha = 1,
  family = "binomial"
)

plot(cv_fit)

# predictors selected by Lasso
coef(cv_fit, s = "lambda.1se")

lasso_formula <- target ~ cellular + negative_emp + 
  low_cpi + high_cci + low_euribor + university + 
  job_student + job_retired + month_sep + month_oct + 
  month_dec + month_mar + p_failure + p_success

lasso_mod<-glm(lasso_formula, data=full_df, family=binomial)
```

### Comperison
```{r}
summary(stepwise)
summary(lasso_mod)

# Compare the models
stepwise_results <- k_fold_mod(data = full_df, target_col = "target", model_formula = stepwise)
lasso_results    <- k_fold_mod(data = full_df, target_col = "target", model_formula = lasso_mod)

print(stepwise_results)
print(lasso_results)

# Threshold evaluation
probs_stepwise <- predict(stepwise, type = "response")
probs_lasso    <- predict(lasso_mod, type = "response")

res_step_05 <- evaluate_threshold(probs_stepwise, target, 0.5)
res_step_02 <- evaluate_threshold(probs_stepwise, target, 0.2)

res_lasso_05 <- evaluate_threshold(probs_lasso, target, 0.5)
res_lasso_02 <- evaluate_threshold(probs_lasso, target, 0.2)


# Unisci tutti i risultati in una lista
results_list <- list(
  Stepwise_0.5 = res_step_05,
  Stepwise_0.2 = res_step_02,
  LASSO_0.5    = res_lasso_05,
  LASSO_0.2    = res_lasso_02
)

# Trasforma in data.frame
results_df <- do.call(rbind, lapply(names(results_list), function(name) {
  res <- results_list[[name]]
  model <- sub("_.*", "", name)
  threshold <- res$Threshold
  data.frame(
    Model       = model,
    Threshold   = threshold,
    Accuracy    = res$Accuracy,
    F1          = res$F1,
    Sensitivity = res$Sensitivity,
    Specificity = res$Specificity
  )
}))

# Visualizza il risultato
print(results_df)

```


### LDA

#### Models
```{r, echo=FALSE}
lda_full_model <- lda(target ~ ., data = full_df)

lda_stepwise_model <- lda(stepwise_formula, data = full_df)

lda_lasso_model <- lda(lasso_formula, data = full_df)
```

#### CV
```{r}
results_lda_full <- cv_lda_eval(full_df, target ~ ., model_name = "LDA_Full", k = 10)

results_lda_stepwise <- cv_lda_eval(full_df,stepwise_formula, model_name = "LDA_Stepwise", k = 10)

results_lda_lasso <- cv_lda_eval(full_df, lasso_formula, model_name = "LDA_LASSO", k = 10)
```

#### Evaluate

```{r}
lda_results <- rbind(results_lda_full, results_lda_stepwise, results_lda_lasso)

aggregate(cbind(Accuracy, F1, Sensitivity, Specificity) ~ Model + Optimized_For, data = lda_results, mean)
aggregate(Threshold ~ Model + Optimized_For, data = lda_results, mean)
```


#### Best LDA

```{r}
print(lda_lasso_model)

probs <- predict(lda_lasso_model)$posterior[, "1"]
pred_class <- ifelse(probs > 0.16, 1, 0)
table(Predicted = pred_class, Actual = full_df$target)

evaluate_threshold(probs, full_df$target, threshold = 0.16)
```

#### ROC Curve

```{r}
roc_obj <- roc(full_df$target, probs)
plot(roc_obj, main = "ROC Curve for LDA LASSO Model")
auc(roc_obj)
```


### QDA

#### Models
```{r, echo=FALSE}
qda_full_model     <- qda(target ~ ., data = full_df)
qda_stepwise_model <- qda(stepwise_formula, data = full_df)
qda_lasso_model    <- qda(lasso_formula, data = full_df)
```

#### CV
```{r}
results_qda_full     <- cv_qda_eval(full_df, target ~ ., model_name = "QDA_Full", k = 10)
results_qda_stepwise <- cv_qda_eval(full_df, stepwise_formula, model_name = "QDA_Stepwise", k = 10)
results_qda_lasso    <- cv_qda_eval(full_df, lasso_formula, model_name = "QDA_LASSO", k = 10)
```

#### Evaluate
```{r}
qda_results <- rbind(results_qda_full, results_qda_stepwise, results_qda_lasso)

aggregate(cbind(Accuracy, F1, Sensitivity, Specificity) ~ Model + Optimized_For, data = qda_results, mean)
aggregate(Threshold ~ Model + Optimized_For, data = qda_results, mean)
```

#### Best QDA
```{r}
print(qda_lasso_model)

probs_qda <- predict(qda_lasso_model)$posterior[, "1"]
pred_class_qda <- ifelse(probs_qda > 0.4, 1, 0)
table(Predicted = pred_class_qda, Actual = full_df$target)

evaluate_threshold(probs_qda, full_df$target, threshold = 0.4)
```

#### ROC Curve
```{r}
roc_qda <- roc(full_df$target, probs_qda)
plot(roc_qda, main = "ROC Curve for QDA LASSO Model")
auc(roc_qda)
```

