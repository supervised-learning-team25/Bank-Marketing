## Model selection

```{r, echo=FALSE}
source("../R/MS_functions.R")
```


### Preprocessing
Based on the Exploratory Data Analysis (EDA), we selected only the most relevant variables.

With a view to training the model, we apply **one-hot encoding**. We obtain the following dataset:

```{r, echo=FALSE}
train_bin <- train

train_bin$cons.price.idx <- ifelse(train_bin$cons.price.idx < 93, 1, 0)
names(train_bin)[names(train_bin) == "cons.price.idx"] <- "low_cpi"

train_bin$cons.conf.idx <- ifelse(train_bin$cons.conf.idx > median(train$cons.conf.idx), 1, 0)
names(train_bin)[names(train_bin) == "cons.conf.idx"] <- "high_cci"

train_bin$euribor3m <- ifelse(train_bin$euribor3m < mean(train$euribor3m), 1, 0)
names(train_bin)[names(train_bin) == "euribor3m"] <- "low_euribor"

train_bin$emp.var.rate <- ifelse(train_bin$emp.var.rate < 0, 1, 0)
names(train_bin)[names(train_bin) == "emp.var.rate"] <- "negative_emp"

train_bin$university<-ifelse(train_bin$education=='university.degree', 1, 0)
train_bin$p_course<-ifelse(train_bin$education=='professional.course', 1, 0)
train_bin <- subset(train_bin, select = -education)

train_bin$job_student <- ifelse(train_bin$job == "student", 1, 0)
train_bin$job_retired <- ifelse(train_bin$job == "retired", 1, 0)
train_bin$job_admin <- ifelse(train_bin$job == "admin.", 1, 0)
train_bin <- subset(train_bin, select = -job)

train_bin$month_sep <- ifelse(train_bin$month == "sep", 1, 0)
train_bin$month_oct <- ifelse(train_bin$month == "oct", 1, 0)
train_bin$month_dec <- ifelse(train_bin$month == "dec", 1, 0)
train_bin$month_mar <- ifelse(train_bin$month == "mar", 1, 0)

train_bin$p_failure <- ifelse(train_bin$poutcome == "failure", 1, 0)
train_bin$p_success <- ifelse(train_bin$poutcome == "success", 1, 0)
train_bin <- subset(train_bin, select = -poutcome)

train_bin$contact <- ifelse(train_bin$contact == "cellular", 1, 0)
names(train_bin)[names(train_bin) == "contact"] <- "cellular"

train_bin$marital <- ifelse(train_bin$marital == "single", 1, 0)
names(train_bin)[names(train_bin) == "marital"] <- "single"

train_bin$campaign <- ifelse(train_bin$campaign > 5, 0, 1)
names(train_bin)[names(train_bin) == "campaign"] <- "low_call"

```

```{r, echo=FALSE}
drop_var<-c('pdays', "default", 'housing' ,"loan", "day_of_week", 
            "month", "nr.employed", 'job', "duration")

full_df <- train_bin[, !(names(train_bin) %in% drop_var)]
full_df$target <-ifelse(subscribed=='yes', 1, 0)
full_df<-full_df[, !(names(full_df)) %in% 'subscribed']
detach(train)
attach(full_df)
```

```{r, echo=FALSE}
varDf <- data.frame(
  Variable = names(full_df),
  Type = c("int", "bool", "bool", "bool", "int", "bool", "bool", "bool", "bool", "bool", "bool", "bool", "bool", "bool", "bool", "bool", "bool", "bool", "bool", "bool", "bool")
)

kable(varDf, align = "ll", caption = "21 Variable") %>%
kable_styling(full_width = TRUE, position = "center", bootstrap_options = "striped")
```

### STEPWISE selection

```{r}
full_model <- glm(target ~ ., data = full_df, family = binomial)
stepwise <- stepAIC(full_model, direction = "both", trace = FALSE)
vif(stepwise)

# predictore removed by Stepwise
stepwise$anova

stepwise_formula <- target ~ single + cellular + low_call + previous + negative_emp + 
  low_cpi + high_cci + low_euribor + university + p_course + 
  job_student + job_retired + job_admin + month_sep + month_oct + 
  month_dec + month_mar + p_failure + p_success
```

### LASSO selection
```{r}
set.seed(123)

df_no_target <- subset(full_df, select = -target)

fit_lasso <- glmnet(x = as.matrix(df_no_target),
                    y = target,
                    alpha = 1,
                    family = "binomial",
)

cv_fit <- cv.glmnet(
  x = as.matrix(df_no_target),
  y = target,
  alpha = 1,
  family = "binomial"
)

plot(cv_fit)

# predictors selected by Lasso
coef(cv_fit, s = "lambda.1se")

lasso_formula <- target ~ cellular + negative_emp + 
  low_cpi + high_cci + low_euribor + university + 
  job_student + job_retired + month_sep + month_oct + 
  month_dec + month_mar + p_failure + p_success

lasso_mod<-glm(lasso_formula, data=full_df, family=binomial)
```

### Comperison
```{r}
summary(stepwise)
summary(lasso_mod)

# Compare the models
stepwise_results <- k_fold_mod(data = full_df, target_col = "target", model_formula = stepwise)
lasso_results    <- k_fold_mod(data = full_df, target_col = "target", model_formula = lasso_mod)

print(stepwise_results)
print(lasso_results)

# Threshold evaluation
probs_stepwise <- predict(stepwise, type = "response")
probs_lasso    <- predict(lasso_mod, type = "response")

res_step_05 <- evaluate_threshold(probs_stepwise, target, 0.5)
res_step_02 <- evaluate_threshold(probs_stepwise, target, 0.2)

res_lasso_05 <- evaluate_threshold(probs_lasso, target, 0.5)
res_lasso_02 <- evaluate_threshold(probs_lasso, target, 0.2)


# Unisci tutti i risultati in una lista
results_list <- list(
  Stepwise_0.5 = res_step_05,
  Stepwise_0.2 = res_step_02,
  LASSO_0.5    = res_lasso_05,
  LASSO_0.2    = res_lasso_02
)

# Trasforma in data.frame
results_df <- do.call(rbind, lapply(names(results_list), function(name) {
  res <- results_list[[name]]
  model <- sub("_.*", "", name)
  threshold <- res$Threshold
  data.frame(
    Model       = model,
    Threshold   = threshold,
    Accuracy    = res$Accuracy,
    F1          = res$F1,
    Sensitivity = res$Sensitivity,
    Specificity = res$Specificity
  )
}))

# Visualizza il risultato
print(results_df)

```


### LDA

#### Models
```{r, echo=FALSE}
lda_full_model <- lda(target ~ ., data = full_df)

lda_stepwise_model <- lda(stepwise_formula, data = full_df)

lda_lasso_model <- lda(lasso_formula, data = full_df)
```

#### CV
```{r}
results_lda_full <- cv_lda_eval(full_df, target ~ ., model_name = "LDA_Full", k = 10)

results_lda_stepwise <- cv_lda_eval(full_df,stepwise_formula, model_name = "LDA_Stepwise", k = 10)

results_lda_lasso <- cv_lda_eval(full_df, lasso_formula, model_name = "LDA_LASSO", k = 10)
```

#### Evaluate

```{r}
lda_results <- rbind(results_lda_full, results_lda_stepwise, results_lda_lasso)

aggregate(cbind(Accuracy, F1, Sensitivity, Specificity) ~ Model + Optimized_For, data = lda_results, mean)
aggregate(Threshold ~ Model + Optimized_For, data = lda_results, mean)
```


#### Best LDA

```{r}
print(lda_lasso_model)

probs <- predict(lda_lasso_model)$posterior[, "1"]
pred_class <- ifelse(probs > 0.16, 1, 0)
table(Predicted = pred_class, Actual = full_df$target)

evaluate_threshold(probs, full_df$target, threshold = 0.16)
```

#### ROC Curve

```{r}
roc_obj <- roc(full_df$target, probs)
plot(roc_obj, main = "ROC Curve for LDA LASSO Model")
auc(roc_obj)
```


### QDA

#### Models
```{r, echo=FALSE}
qda_full_model     <- qda(target ~ ., data = full_df)
qda_stepwise_model <- qda(stepwise_formula, data = full_df)
qda_lasso_model    <- qda(lasso_formula, data = full_df)
```

#### CV
```{r}
results_qda_full     <- cv_qda_eval(full_df, target ~ ., model_name = "QDA_Full", k = 10)
results_qda_stepwise <- cv_qda_eval(full_df, stepwise_formula, model_name = "QDA_Stepwise", k = 10)
results_qda_lasso    <- cv_qda_eval(full_df, lasso_formula, model_name = "QDA_LASSO", k = 10)
```

#### Evaluate
```{r}
qda_results <- rbind(results_qda_full, results_qda_stepwise, results_qda_lasso)

aggregate(cbind(Accuracy, F1, Sensitivity, Specificity) ~ Model + Optimized_For, data = qda_results, mean)
aggregate(Threshold ~ Model + Optimized_For, data = qda_results, mean)
```

#### Best QDA
```{r}
print(qda_lasso_model)

probs_qda <- predict(qda_lasso_model)$posterior[, "1"]
pred_class_qda <- ifelse(probs_qda > 0.4, 1, 0)
table(Predicted = pred_class_qda, Actual = full_df$target)

evaluate_threshold(probs_qda, full_df$target, threshold = 0.4)
```

#### ROC Curve
```{r}
roc_qda <- roc(full_df$target, probs_qda)
plot(roc_qda, main = "ROC Curve for QDA LASSO Model")
auc(roc_qda)
```
